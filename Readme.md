# Хеш-таблица

## Цель работы

1. Реализовать базовые функции хеш-таблицы: поиск элемента, добавление элемента, удаление элемента.

1. Протестировать различные хеш-функций на равномерное распределение коллизий.

1. Оптимизировать хеш-таблицу по скорости аппаратными методами ([`SIM-D` инструкции], [`inline` ассемблер], [написание функции на ассемблере]). Найти узкие места программы и ускорить работу основных функций: вставки, удаления и поиска. Показать, что дальнейшие попытки оптимизации только ухудшают производительность / читаемость кода / модульность программы.

## Теоретическое введение

`Хеш-таблица` - это структура данных, которая позволяет быстро находить, добавлять и удалять элементы. В среднем поиск, вставка и удаление выполняются за `O(1)`.

Хеш-таблица содержит массив данных. Выполнение операции начинается с вычисления `хеш-функции`, которая каждому значению сопоставляет его индекс в массиве. При этом неизбежны `коллизии` - ситуации когда двум разным значениям хеш-функция сопоставляет один и тот же индекс. Существует два способа разрешения коллизий: `открытая адресация` (более подробную информацию об этом методе можно получить в [интернете](https://ru.wikipedia.org/wiki/Хеш-таблица#Открытая_адресация)) и `метод цепочек`.

В данной работе реализована хеш-таблица методом цепочек. Элементами массива хеш-таблицы являются связные списки. После вычисления хеш-функции, выполняемая операция перенаправляется соответствующему списку. Например, рассмотрим добавление элемента в хеш-таблицу. Сначала вычисляется хеш-функция - её значение будет индексом списка в массиве. Далее элемент добавляется в этот список. Обычно новый элемент добавляют в конец списка. При правильно подобранном размере хеш-таблицы, все списки содержат 1-2 элемента, поэтому поиск чаще всего осуществляется перебором.

<p align="center">
    <img src="images/Hashtable list method.png" width="600"/>
    <p align="center">Рисунок 1. Разрешение коллизий методом цепочек.</p>
</p>

В идеальном случае хеш-функция разным элементам хеш-таблицы сопоставляет разные индексы. В реальности это не так. Некоторые хеш-функции обладают `неравномерным распределением коллизий`: функция принимает одно и то же значение для большого набора аргументов. Такие `концентрации коллизий` замедляют работу хеш-таблицы, так как возникают перегруженные элементами списки и операции поиска и удаления начинают выполняться за `O(n)`. Такие хеш-функции не рекомендуется использовать для хеш-таблицы.

Хеш-функции, обладающие равномерным распределением коллизий, позволяют осуществлять операции с хеш-таблицей за примерно одинаковое время. При этом в каждом списке находится почти одно и тоже количество элементов.

На рисунке приведен пример хеш-функций, имеющих неравномерное и равномерное распределения коллизий.

<p align="center">
    <img src="images/Collisions.png" width="600"/>
    <p align="center">Рисунок 2. Распределение коллизий хеш-функций.</p>
</p>

## Исследование хеш-функций на распределение коллизий

В данной работе будем хранить в таблице слова. Исследуем следующие функции на равномерное распределение коллизий:

1. `Всегда единица`. Функция, сопоставляющая всем словам одно и тоже значение, равное 1.

1. `ASCII-код первого символа`. Функция, сопоставляющая слову `ASCII-код` первой буквы.

1. `Длина слова`. Функция, сопоставляющая слову, его длину.

1. `Сумма ASCII-кодов букв`. Функция, сопоставляющая слову, сумму его `ASCII-символов`.

1. `Ror`. Функция, содержащая циклический сдвиг вправо. Код на `C++`:
    ```C++
        // word - указатель на слово, оканчивающееся '\0'
        size_t Hash_Ror(char* word)
        {
            size_t hash = *word++;

            while (*word)
            {
                hash = ((hash & 1) << (8 * sizeof(size_t) - 1)) | (hash >> 1); // Циклический сдвиг вправо
                hash ^= *word++;
            }

            return hash;
        }
    ```

1. `CRC-32`. Последней хеш-функцией будет CRC-32.

### Методика исследования

Тестировать хеш-функции будем на произведениях Шекспира. Словами будем считать формально последовательности латинских заглавных и строчных букв, разделенных любыми другими символами. Слова чувствительны к регистру. Всего слов в наборе данных `~1 000 000`, из них различны `~30 000`.

Протестируем функции на разных количествах списков в хеш-таблице: 20, 100, 1500, 15000.

Номером списка, в который нужно поместить слово, будет значение хеш-функции по модулю количества списков: `listIndex = hash % listCount`.

### Предварительный анализ хеш-функций

Ожидается, что первые четыре функции будут давать не равномерное распределение коллизий:

1. `Всегда единица`. Все элементы хеш-таблицы будут храниться в одном списке, остальные списки будут пустыми. Очевидно, что распределение не равномерно.

1. `ASCII-код первого символа`. Множество значений функции ограничено 256. В нашей задаче слова начинаются с букв английского алфавита (26 букв, 2 регистра), то есть у функции всего 26 * 2 = 52 значения.

1. `Длина слова`. Большинство слов не превышают 32 символа.

1. `Сумма ASCII-кодов букв`. Количество значений этой функции можно оценить сверху следующим образом: наибольшее число букв 32, наибольшее значение ASCII-кода z = 122. То есть 122 * 32 = 3904 значений. Проведя измерения, увидим, что наибольшая сумма ASCII-кодов букв 2892, наименьшая 65, а средняя 750.

### Проведение измерений

Все изображения графиков хранятся в папках `images/group functions/` и `images/group lists/`. Графики построены в двух вариантах: группировка по типу функции (`hash_<functionName>.png`) и группировка по количеству списков в хеш-таблице (`hash_list_<listCount>.png`). В отчёте приведем и проанализируем графики с группировкой по типу функции как более наглядные.

На данных графиках по оси `x` откладывается индекс списка в хеш-таблице. По оси `y` откладывается количество элементов данного списка при заполненной словами таблице, то есть количество коллизий исследуемой функции. Горизонтальная красная линия на графике показывает число коллизий, если бы функция была идеальной. То есть если график функции совпадает с красной линией, то можно говорить о равномерном распределении функции на данном наборе данных, при данном размере хеш-таблицы. Если же изменить набор входных данных или размер хеш-таблицы, то распределение может измениться. Как будет видно далее, для некоторых функций при мелом размере хеш-таблицы распределение равномерно, а при больших размерах становится неравномерным.

При больших размерах хеш-таблицы построение столбчатых диаграмм `matplotlib.pyplot.bar()` затрудняется. Во-первых, отрисовка графика в `Python` начинает занимать значительное время. Во-вторых, столбики становятся слишком узкими так, что теряются некоторые значения графике. Эту проблему можно решить, если строить график `matplotlib.pyplot.plot()` и закрашивать область под ним `matplotlib.pyplot.fill_between()`. Но тогда перестают быть видны пустые списки. То есть при большом размере хеш-таблицы нет идеального варианта, поэтому будем использовать два способа.

Обозначим описанные выше способы, как `I` - построение столбчатых диаграмм, `II` - построение графика и закрашивание области под ним. При малом размере хеш-таблицы (20 и 100) будем использовать только `I` способ. При больших количествах списков (1500 и 15000) для графиков с группировкой по количеству списков в хеш-таблице `images/group lists/` будем использовать только `II` способ. Для группировки по типу функции построим графики при большом количестве списков как первым `I` (`images/group functions/bar/`), так и вторым `II` (`images/group functions/plot/`) способом. Далее в отчёте будет указано, каким способом был построен данный график. Также в скобках будет приведено описание, почему был выбран тот или иной способ.

Сравнить графики, построенные разными способами, предлагается читателю самостоятельно. Также читателю предоставляется возможность проанализировать графики, построенные с другим типом группировки (по количеству списков).

1. `Всегда единица`. График при больших размерах хеш-таблицы построен `II` способом (Первый `I` способ не отображает одиночный столбик при 15000 списков). Как и ожидалось график этой функции представлен одним столбцом. В хеш-таблице используется только один список. Это самая плохая хеш-функция.

    <p align="center">
        <img src="images/group functions/plot/hash_const.png" width="600"/>
    </p>

1. `ASCII-код первого символа`. График при больших размерах хеш-таблицы построен `II` способом (При первом `I` способе теряются данные при 1500 и 15000 списках). Данная функция имеет неравномерное распределение при всех размерах хеш-таблицы (количествах списков в ней). Видно, что значения функции находятся примерно в промежутке от 60 до 130.

    <p align="center">
        <img src="images/group functions/plot/hash_letter.png" width="600"/>
    </p>

1. `Длина слова`. График при больших размерах хеш-таблицы построен `II` способом (При первом `I` способе не видно столбиков при 15000 списках). Имеет неравномерное распределение при всех размерах хеш-таблицы. По графикам её множество значений ограничено 16 для большинства слов. Если провести точный подсчёт, то слов длиной 16 и больше окажется всего 7 из 30 000.

    <p align="center">
        <img src="images/group functions/plot/hash_length.png" width="600"/>
    </p>

1. `Сумма ASCII-кодов букв`. График при больших размерах хеш-таблицы построен `II` способом (При первом `I` способе видны пустые списки в промежутке [400; 1100], хотя на самом деле их нет. В этом промежутке все списки содержат элементы, но некоторые из них содержат мало элементов, что `Python` отображает их как пустые полосы, как будто там нет элементов.). При малом размере хеш-таблицы (20 списков) данная функция имеет равномерное распределение. Но уже начиная со 100 списков её распределение становится неравномерным, появляется область концентрации коллизий. Полностью убедиться в неравномерности распределения можно, если посмотреть на 3 график (1500 списков), на котором лучше всего видно неравномерность распределения функции. Данная функция не подходит для использования в хеш-таблице.

    Посчитаем точное количество пустых и переполненных списков.
    |Пустые списки|Число элементов больше среднего|Число элементов не больше среднего|Всего|
    |:-:|:-:|:-:|:-:|
    | 173 | 507 | 820 | 1500|
    | 13661 | 1078 | 261 | 15000|

    <p align="center">
        <img src="images/group functions/plot/hash_char_sum.png" width="600"/>
    </p>

1. `Ror`. График при больших размерах хеш-таблицы построен `I` способом (Для 1500 и 15000 списков при втором `II` способе кажется, что все значения больше среднего, хотя это не так. В основном количество коллизий меньше среднего (см. таблицу ниже)). По первым двум графикам видно, что распределение функции неравномерно. Тем не менее её распределение намного лучше, чем у 4 предыдущих функций.

    Посчитаем точное количество пустых и переполненных списков.
    |Пустые списки|Число элементов больше среднего|Число элементов не больше среднего|Всего|
    |:-:|:-:|:-:|:-:|
    | 296 | 375 | 829 | 1500|
    | 10335 | 2128 | 2537 | 15000|

    <p align="center">
        <img src="images/group functions/bar/hash_ror.png" width="600"/>
    </p>

1. `CRC-32`. График при больших размерах хеш-таблицы построен `I` способом. `Внимание! Для 1500 списков в первом способе I видно, что есть пустые списки, хотя это не так, все списки содержат не меньше 6 элементов`. (Второй способ `II` не отображает пустые списки при 15000). У данной функции распределение лучше, чем у предыдущих. Но оно не идеально: 13% списков пустые при размере хеш-таблицы 15000.

    Посчитаем точное количество пустых и переполненных списков.
    |Пустые списки|Число элементов больше среднего|Число элементов не больше среднего|Всего|
    |:-:|:-:|:-:|:-:|
    | 0 | 699 | 801 | 1500|
    | 1955 | 4980 | 8065 | 15000|

    Заполненность списков при размере хеш-таблицы 15000.

    |Количество элементов в списке|    0 |    1 |    2 |    3 |    4 |    5     |    6 |    7 |    8 |    9 |   10 |
    |----------------------------:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|:----:|
    |Количество списков           | 1955 | 3978 | 4087 | 2779 | 1342 | 579   |  205 | 50   | 21   | 2    | 2    |

    <p align="center">
        <img src="images/group functions/bar/hash_crc32.png" width="600"/>
    </p>

### Вывод

1-5 функции не удачные для хеш-таблицы, так как их распределение неравномерно. Из приведенных функций лучше всего для хеш-таблицы подходит `CRC-32`.

## Оптимизация хеш-таблицы по скорости

### Общая методика оптимизации

 Скорость выполнения программы иногда оценивают асимптотической сложностью алгоритма `O(f(n))`, где `f(n)` - некоторая функция от количества итераций `n` определённого участка кода (например, `f(n) = 1`, `f(n) = n`). `O(f(n)) = k * f(n)` и скорость выполнения определяется не только функцией `f(n)`, но и коэффициентом `k`. Чем больше коэффициент `k`, тем медленнее выполняется программа.

 Оптимизации по производительности чаще делятся на два вида:

 1. `Алгоритмические`. В таких оптимизациях применяется новый, более быстрый алгоритм. С изменением алгоритма меняется характеризующая его асимптотическую сложность функция `f(n)`.

 1. `Аппаратные`. В таких оптимизациях алгоритм не меняют, но стремятся уменьшить коэффициент `k`. При этом функция `f(n)` не изменяется. Таким способом можно добиться большого прироста производительности.

Алгоритм оптимизации следующий:

1. С помощью профилировщика находим `узкие места программы` - участки кода, выполнение которых занимает больше всего времени.

1. Оптимизируем в первую очередь функцию, которая выполняется дольше всего.

    Почему важно сначала оптимизировать высоконагруженные участки кода? Если начать оптимизацию с функций, которые мало выполняются (занимают малый процент от общего времени выполнения программы), то, во-первых, прирост скорости после оптимизации будет незначительным. Во-вторых, многие оптимизации снижают читаемость кода и модульность программы. В-третьих, если потом приступить к оптимизации высоконагруженных функций, то их оптимизация может стать несовместимой с уже написанными оптимизациями слабонагруженных функций. Поэтому оптимизацию программы нужно проводить высоконагруженных функций.

1. После оптимизации снова измеряем время выполнения программы профилировщиком.

1. Далее снова оптимизируем самую высоконагруженную функцию.

    Если самой высоконагруженной функцией является оптимизированная в прошлый раз, и для неё больше не получается придумать оптимизации, то оптимизировать нужно вторую по времени выполнения функцию.

1. Данный процесс стоит повторять, пока заметно ускорение программы.

1. Если оптимизация даёт незначительный прирост производительности, то стоит задуматься о том, чтобы убрать её. Как уже говорилось ранее, оптимизации могут ухудшать читаемость кода и модульность программы. Это может привести к трудностям при дальнейшей поддержке и масштабировании проекта. При этом если оптимизация не даёт заметный прирост производительности, то она приносит не пользу, а вред, и стоит отказаться от такой оптимизации.

### Особенности оптимизации хеш-таблицы

В данной работе основной акцент делается на аппаратных оптимизациях. В хеш-таблице будут ускоряться основные функции: поиска, вставки и удаления элементов, потому что во время обычной работы они выполняются больше всего. При этом не имеет смысла оптимизировать, например, функцию чтения слов из файла, так как она выполняется один раз в начале работы с хеш-таблицей.

В самом начале нужно использовать функцию, имеющую равномерное распределение коллизий. Тогда операции со всеми элементами будут выполняться за одно и тоже время. В первой части работы было показано, что `CRC-32` имеет самое удачно для хеш-таблицы распределение, поэтому будем использовать именно эту хеш-функцию.

Потом нужно правильно настроить размер хеш-таблицы. В рабочем состоянии в каждом списке должно быть примерно 1-2 слова. Тогда все операции будут выполняться быстро, в оптимизациях может отсутствовать необходимость, так как они будут давать минимальный прирост производительности. Так как данная работа учебная, то чтобы можно было сделать несколько оптимизаций, установим размер хеш-таблицы так, чтобы в каждом списке в среднем было 20-30 слов.

Все три операции (поиска, вставки и удаления) содержат вычисление хеш-функции. Реализованная хеш-таблица не может хранить одинаковые слова, поэтому перед вставкой необходимо проверить, добавлено ли уже это слово. При удалении, нужно сначала найти слово в списке, а затем удалить его. Поэтому все три операции также содержат поиск элемента в списке по индексу. Из этого следует, что скорее всего придется оптимизировать именно функцию вычисления хеша и поиска элемента в списке.

При оптимизации вставки и удаления элемента, важно правильно подобрать размер списков в хеш-таблице. Если его настроить слишком маленьким, то будет много выделений памяти. Тогда может оказаться, что самая нагруженная функция это `calloc`, который крайне сложно оптимизировать. Поэтому настроим размер списков так, чтобы во время работы хеш-таблицы было 0 выделений памяти.

### Опции компиляции, условия тестирования

Программа компилировалась с помощью `Microsoft Visual Studio Community 2022`. Для поиска узких мест использовался встроенный в `Visual Studio` профилировщик.

Обозначим следующие опции компиляции:

1. Максимальная оптимизация программы. `CompReleaseMax`: `Release x64`, `/O2`, favor speed `/Ot`, enable intrinsic functions `/Oi`, inline function expansion any suitable `/Ob2`, whole program optimization `/GL`, enable enchanced instruction set `/arch:SSE2`, link time code generation `/LTCG`.

1. Опции компиляции для профилирования и поиска узких мест. `CompReleaseProfiling`: `Release x64`, `/O2`, favor speed `/Ot`, enable intrinsic functions `/Oi`, inline function expansion disabled `/Ob0`, whole program optimization `No`, enable enchanced instruction set `/arch:SSE2`, link time code generation `Default`.

`CompReleaseProfiling` отличается от `CompReleaseMax` тем, что у него выключены `inline` функции, полная оптимизация программы и кодогенерация во время компоновки. Сделано это для того, чтобы можно было анализировать результат измерения производительности, так как `CompReleaseMax` очень сильно оптимизирует программу, и нельзя найти узкое место в программе. `CompReleaseMax` активно использует inline-расширение функций и в итоге в программе остаётся 2-3 функции, которые выполняется 90% времени. По таким данным нельзя определить функции, которые нужно оптимизировать.

Тестировать работу хеш-таблицы будем на том же наборе текстов Шекспира, на котором исследовалась равномерность распределения коллизий хеш-функций. Слов в текстах, включая повторяющиеся, ~1 000 000. Различных слов в заполненной хеш-таблице будет ~30 000.
Установим размер хеш-таблицы 1 500, чтобы в каждом списке было примерно 20-30 слов.

Чтобы правильно найти узкие места программы, нужно уменьшить вклад во время выполнения программы функций, которые выполняются один раз при инициализации таблицы. Для этого будем вызывать оптимизируемую функцию ~10^9 раз. Тогда профилировщик правильно покажет какая функция самая нагруженная.

При разных запусках время выполнения программы может колебаться около среднего значения. Чтобы получить достоверную оценку времени выполнения программы, измерять время профилировщиком будем 3 раза, а затем усредним полученные данные. Также вычислим среднеквадратичное отклонения для общего времени измерения. На изображениях приводятся результаты первого профилирования.

### Измерение времени работы не оптимизированной программы `CompReleaseProfiling`

#### Поиск элемента в хеш-таблице

|№ измерения               |1      |2      |3      |
|-------------------------:|:-----:|:-----:|:-----:|
|Общее время выполнения, мc|154 836|159 009|154 505|

Среднее время выполнения 156 ± 3 с

<p align="center">
    <img src="Profiling/find unoptimized release.png" width="600"/>
</p>

#### Вставка-удаление элемента

|№ измерения               |1      |2      |3      |
|-------------------------:|:-----:|:-----:|:-----:|
|Общее время выполнения, мc|279 576|283 304|280 749|

Среднее время выполнения 281 ± 2 с

<p align="center">
    <img src="Profiling/insert-remove unoptimized release.png"  width="600"/>
</p>

#### Анализ результата

Самой нагруженной является функция поиска элемента в списке `ListFind`. Она содержит `ListComparator` - функцию, сравнивающую два слова. На втором месте находится `HashTable_HashCRC32_C` - функция вычисления хеша `CRC32` и `CalcHash` - обертка над `HashTable_HashCRC32_C`, которая значению хеш-функции сопоставляет индекс списка, который соответствует данному слову.

Запустим программу с опциями компиляции `CompReleaseMax` и посмотрим, насколько быстрее она будет выполняться по сравнению с `CompReleaseProfiling`.

### Измерение времени работы не оптимизированной программы `CompReleaseMax`

#### Поиск элемента в хеш-таблице

|№ измерения               |1      |2      |3      |
|-------------------------:|:-----:|:-----:|:-----:|
|Общее время выполнения, мc|140 005|139 716|141 084|

Среднее время выполнения 140 ± 1 с

<p align="center">
    <img src="Profiling/find unoptimized releaseMax.png" width="600"/>
</p>

#### Вставка-удаление элемента

|№ измерения               |1      |2      |3      |
|-------------------------:|:-----:|:-----:|:-----:|
|Общее время выполнения, мc|270 763|259 610|277 511|

Среднее время выполнения 269 ± 9 с

<p align="center">
    <img src="Profiling/insert-remove unoptimized releaseMax.png"  width="600"/>
</p>

#### Анализ результата

Тесты поиска выполняются на 156 - 140 = 16 с быстрее.

Тесты вставки-удаления выполняются на 281 - 269 = 12 с быстрее.

Первой оптимизацией ускорим поиск элемента в списке, как самую нагруженную функцию.

### Оптимизация типа данных

Проанализируем набор входных данных: длина слова в основном не превышает 16 символов. Слов длиной 15 символов всего 33, длиной 16 - всего 3, длиной больше 16 - всего 4. Если пренебречь словами длиной больше 16 символов, то можно изменить тип данных слов с `char*` на `__m128i`. Слово будет храниться в 16 байтовой переменной, компилятор сможет сравнивать слова двумя сравнениями 64-битных регистров, что выполняется быстрее, чем побайтовое сравнение слов.

Измерим время выполнения программы с опциями компиляции `CompReleaseProfiling`.

#### Поиск элемента в хеш-таблице

|№ измерения               |1      |2      |3      |
|-------------------------:|:-----:|:-----:|:-----:|
|Общее время выполнения, мc|77 847|77 518|77 986|

Среднее время выполнения 77,8 ± 0,3 с

<p align="center">
    <img src="Profiling/find type optimization release.png"  width="600"/>
</p>

#### Вставка-удаление элемента

|№ измерения               |1      |2      |3      |
|-------------------------:|:-----:|:-----:|:-----:|
|Общее время выполнения, мc|148 337|149 892|148 694|

Среднее время выполнения 149,0 ± 0,8 с

<p align="center">
    <img src="Profiling/insert-remove type optimization release.png"  width="600"/>
</p>

#### Анализ результата

Изменение типа данных ускорило поиск и вставку-удаление в 2 раза по сравнению с версией без оптимизации (везде опции `CompReleaseProfiling`). Подчеркнем, что данная оптимизация основана на частном случае, и компилятор никогда не сможет применить её. В условиях данной задачи удалось применить такую оптимизацию, но в общем случае её применить не получиться. При данной оптимизации производительность повышается, но общность решения задачи пропадает.

Следующей самой нагруженной функцией является вычисление хеша, поэтому будем оптимизировать её.

### Оптимизация хеш-функции

Заменим функцию вычисления контрольной суммы на `SIM-D` инструкцию `_mm_crc32_u64`. Тогда хеш будет считаться за две инструкции.

Измерим время выполнения программы с опциями компиляции `CompReleaseProfiling`.

#### Поиск элемента в хеш-таблице

|№ измерения               |1      |2      |3      |
|-------------------------:|:-----:|:-----:|:-----:|
|Общее время выполнения, мc|29 753|29 567|29 700|

Среднее время выполнения 29,6 ± 0,1 с

<p align="center">
    <img src="Profiling/find hash optimization release.png"  width="600"/>
</p>

#### Вставка-удаление элемента

|№ измерения               |1      |2      |3      |
|-------------------------:|:-----:|:-----:|:-----:|
|Общее время выполнения, мc|50 368|51 369|50 233|

Среднее время выполнения 50,6 ± 0,6 с

<p align="center">
    <img src="Profiling/insert-remove hash optimization release.png"  width="600"/>
</p>

#### Анализ результата

Изменение типа данных ускорило поиск в 2,6 раза и вставку-удаление в 2,9 раза по сравнению с предыдущей версией.

Найдем общий прирост производительности. Поиск ускорился в 5,3 раза, а вставка-удаление в 5,4 раза.

Если посмотреть на результаты профилирования, то можно увидеть, что самыми нагруженными функциями опять являются поиск элемента в списке и вычисление хеш-функции. В результатах профилирования вставки-удаления элементов видно, что удаление элемента из таблицы `HashTableRemove` и добавление элемента в таблицу `HashTableInsert` занимают 9% и 8% соответственно от общего времени выполнения. Однако оптимизировать их не получится, так как при попытке переписать их на ассемблере или добавить `inline`-ассемблерную вставку, модульность программы резко ухудшится. Частные случаи применить к этим функциям тоже не получится.

Так как данная задача учебная, и в задании было переписать функцию на ассемблере и применить `inline`-ассемблер, то применим эти виды оптимизации к самой нагруженной функции - вычисления хеша. Ожидается, что эти оптимизации не дадут никакого прироста производительности, но ухудшат модульность программы и читаемость кода. В реальном проекте можно остановиться на применение в хеш-функции `SSE` инструкции.
